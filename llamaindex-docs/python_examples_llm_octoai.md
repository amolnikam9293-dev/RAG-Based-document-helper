[Skip to content](https://developers.llamaindex.ai/python/examples/llm/octoai/#_top)
# OctoAI 
If you‚Äôre opening this Notebook on colab, you will probably need to install LlamaIndex ü¶ô.
```


%pip install llama-index-llms-octoai




%pip install llama-index




%pip install octoai-sdk


```

Include your OctoAI API key below. You can get yours at [OctoAI](https://octo.ai).
[Here](https://octo.ai/docs/getting-started/how-to-create-an-octoai-access-token) are some instructions in case you need more guidance.
```


OCTOAI_API_KEY=""


```

#### Initialize the Integration with the default model
[Section titled ‚ÄúInitialize the Integration with the default model‚Äù](https://developers.llamaindex.ai/python/examples/llm/octoai/#initialize-the-integration-with-the-default-model)
```


from llama_index.llms.octoai import OctoAI





octoai =OctoAI(token=OCTOAI_API_KEY)


```

#### Call `complete` with a prompt
[Section titled ‚ÄúCall complete with a prompt‚Äù](https://developers.llamaindex.ai/python/examples/llm/octoai/#call-complete-with-a-prompt)
```


response = octoai.complete("Paul Graham is ")




print(response)


```

#### Call `chat` with a list of messages
[Section titled ‚ÄúCall chat with a list of messages‚Äù](https://developers.llamaindex.ai/python/examples/llm/octoai/#call-chat-with-a-list-of-messages)
```


from llama_index.core.llms import ChatMessage





messages =[




ChatMessage(




role="system",




content="Below is an instruction that describes a task. Write a response that appropriately completes the request.",





ChatMessage(role="user",content="Write a blog about Seattle"),





response = octoai.chat(messages)




print(response)


```

## Streaming
[Section titled ‚ÄúStreaming‚Äù](https://developers.llamaindex.ai/python/examples/llm/octoai/#streaming)
Using `stream_complete` endpoint
```


response = octoai.stream_complete("Paul Graham is ")




forin response:




print(r.delta,end="")


```

Using `stream_chat` with a list of messages
```


from llama_index.core.llms import ChatMessage





messages =[




ChatMessage(




role="system",




content="Below is an instruction that describes a task. Write a response that appropriately completes the request.",





ChatMessage(role="user",content="Write a blog about Seattle"),





response = octoai.stream_chat(messages)




forin response:




print(r.delta,end="")


```

## Configure Model
[Section titled ‚ÄúConfigure Model‚Äù](https://developers.llamaindex.ai/python/examples/llm/octoai/#configure-model)
```

# To customize your API token, do this


# otherwise it will lookup OCTOAI_TOKEN from your env variable



octoai =OctoAI(




model="mistral-7b-instruct",max_tokens=128,token=OCTOAI_API_KEY






response = octoai.complete("Paul Graham is ")




print(response)


```

