[Skip to content](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#_top)
# Full-Stack Projects
We’ve created both tooling and a variety of example projects (all open-source) to help you get started building a full-stack LLM application.
## create-llama
[Section titled “create-llama”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#create-llama)
`create-llama` is a command-line tool that will generate a full-stack application template for you. It supports both FastAPI, Vercel, and Node backends. This is one of the easiest ways to get started!
Resources:
  * [create-llama Additional Templates](https://github.com/jerryjliu/create_llama_projects)


## Full-Stack Applications
[Section titled “Full-Stack Applications”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#full-stack-applications)
The LlamaIndex team has also built some in-house projects - all of them open-sourced with MIT license - that you can use out of the box, or use as a template to kickstart your own project.
Check them out below.
### SEC Insights
[Section titled “SEC Insights”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#sec-insights)
  * [SEC Insights App](https://secinsights.ai/)


### Chat LlamaIndex
[Section titled “Chat LlamaIndex”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#chat-llamaindex)
  * [Chat LlamaIndex App](https://chat-llamaindex.vercel.app/)
  * [Chat LlamaIndex Repo](https://github.com/run-llama/chat-llamaindex)


### RAGs
[Section titled “RAGs”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#rags)
[RAGs Repo](https://github.com/run-llama/rags)
### RAG CLI
[Section titled “RAG CLI”](https://developers.llamaindex.ai/python/framework/community/full_stack_projects/#rag-cli)
