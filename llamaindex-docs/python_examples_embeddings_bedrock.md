[Skip to content](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#_top)
# Bedrock Embeddings 
If you‚Äôre opening this Notebook on colab, you will probably need to install LlamaIndex ü¶ô.
```


%pip install llama-index-embeddings-bedrock


```

```


import os





from llama_index.embeddings.bedrock import BedrockEmbedding


```

```


embed_model =BedrockEmbedding(




aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),




aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),




aws_session_token=os.getenv("AWS_SESSION_TOKEN"),




region_name="<aws-region>",




profile_name="<aws-profile>",



```

```


embedding = embed_model.get_text_embedding("hello world")


```

## List supported models
[Section titled ‚ÄúList supported models‚Äù](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#list-supported-models)
To check list of supported models of Amazon Bedrock on LlamaIndex, call `BedrockEmbedding.list_supported_models()` as follows.
```


from llama_index.embeddings.bedrock import BedrockEmbedding




import json





supported_models = BedrockEmbedding.list_supported_models()




print(json.dumps(supported_models,indent=2))


```

## Provider: Amazon
[Section titled ‚ÄúProvider: Amazon‚Äù](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#provider-amazon)
Amazon Bedrock Titan embeddings.
```


from llama_index.embeddings.bedrock import BedrockEmbedding





model =BedrockEmbedding(model_name="amazon.titan-embed-g1-text-02")




embeddings = model.get_text_embedding("hello world")




print(embeddings)


```

## Provider: Cohere
[Section titled ‚ÄúProvider: Cohere‚Äù](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#provider-cohere)
### cohere.embed-english-v3
[Section titled ‚Äúcohere.embed-english-v3‚Äù](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#cohereembed-english-v3)
```


model =BedrockEmbedding(model_name="cohere.embed-english-v3")




coherePayload =["This is a test document", "This is another test document"]





embed1 = model.get_text_embedding("This is a test document")




print(embed1)





embeddings = model.get_text_embedding_batch(coherePayload)




print(embeddings)


```

### MultiLingual Embeddings from Cohere
[Section titled ‚ÄúMultiLingual Embeddings from Cohere‚Äù](https://developers.llamaindex.ai/python/examples/embeddings/bedrock/#multilingual-embeddings-from-cohere)
```


model =BedrockEmbedding(model_name="cohere.embed-multilingual-v3")




coherePayload =[




"This is a test document",




"‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞Ö‡∞®‡±á‡∞¶‡∞ø ‡∞¶‡±ç‡∞∞‡∞æ‡∞µ‡∞ø‡∞° ‡∞≠‡∞æ‡∞∑‡∞≤ ‡∞ï‡±Å‡∞ü‡±Å‡∞Ç‡∞¨‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø‡∞® ‡∞≠‡∞æ‡∞∑.",




"Esto es una prueba de documento multiling√ºe.",




"ÊîªÊÆªÊ©üÂãïÈöä",




"Combien de temps √ßa va prendre ?",




"–î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω",





embeddings = model.get_text_embedding_batch(coherePayload)




print(embeddings)


```

